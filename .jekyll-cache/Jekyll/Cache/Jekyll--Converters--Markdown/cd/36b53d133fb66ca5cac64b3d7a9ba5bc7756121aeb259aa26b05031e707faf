I"1'<h1 id="bronn-music-recommendation-bot">Bronn Music Recommendation Bot</h1>

<p>The <em>Bronn Bot</em> was created to help users find music through a bot developed using the <a href="https://dev.botframework.com">Bot Framework</a>.
In this document we’ll go through how to run Bronn on your local machine, as well has the key components which the bot is built upon.</p>

<p><code class="language-plaintext highlighter-rouge">Demonstration of how Bronn reacts to a neutral user greeting.</code>
<img src="../images/bronn-demo.png" alt="Bronn intro demo" /></p>

<h3 id="prerequisites">Prerequisites</h3>

<h2 id="install-python-36---38">Install Python 3.6 - 3.8</h2>
<p>Currently the bot will only work if you run it using Python versions 3.6 to 3.8</p>

<h2 id="download-the-code">Download the code</h2>
<p>You can find the bot code at its <a href="https://github.com/DirenBodom/Bronn-Bot/tree/master">Github Repository</a>. Make sure that you are using the master branch.</p>

<h2 id="running-the-sample">Running the sample</h2>
<ul>
  <li>Run <code class="language-plaintext highlighter-rouge">pip install -r requirements.txt</code> to install all dependencies</li>
  <li>Run <code class="language-plaintext highlighter-rouge">python app.py</code></li>
</ul>

<h2 id="testing-the-bot-using-bot-framework-emulator">Testing the bot using Bot Framework Emulator</h2>

<p><a href="https://github.com/microsoft/botframework-emulator">Bot Framework Emulator</a> is a desktop application that allows bot developers to test and debug their bots on localhost or running remotely through a tunnel.</p>

<ul>
  <li>Install the Bot Framework Emulator version 4.3.0 or greater from <a href="https://github.com/Microsoft/BotFramework-Emulator/releases">here</a></li>
</ul>

<h3 id="connect-to-the-bot-using-bot-framework-emulator">Connect to the bot using Bot Framework Emulator</h3>

<ul>
  <li>Launch Bot Framework Emulator</li>
  <li>Enter a Bot URL of <code class="language-plaintext highlighter-rouge">http://localhost:3978/api/messages</code></li>
</ul>

<h3 id="key-components">Key Components</h3>

<p>The bot’s main features currently are:</p>
<ul>
  <li>Waterfall dialogs which maintain a continous conversation with the users</li>
  <li>Adaptive cards that provide key information for recommended songs, album art, and a link for the user to learn more about the recommendation</li>
  <li>Default data set of available recommendations, consisting of songs from multiple genres</li>
  <li>Interruption handling that give the user options to end the conversation</li>
  <li>Natural language processing through the Luis AI. This enables detection of user’s feelings and genre detection.</li>
</ul>

<h2 id="dialogs">Dialogs</h2>

<p>There are 2 dialogs which the user interacts with:</p>
<ul>
  <li>MainDialog: Dialog that provides the initial greet and uses recognizer to determine how to launch the RecommendationDialog</li>
  <li>Recommendation: Dialog that computes songs based on user input and keeps the conversation going through repeating the recommendation step.</li>
</ul>

<p>You can see how the MainDialog dialog is created:
<code class="language-plaintext highlighter-rouge">app.py lines 72-79</code></p>
<pre><code class="language-Python3">
# Create the Bot
RECOGNIZER = MusicRecognizer(CONFIG)
RECOMMENDATION_DIALOG = RecommendationDialog(RECOGNIZER)
DIALOG = MainDialog(RECOGNIZER, RECOMMENDATION_DIALOG)
BOT = MyBot(RECOGNIZER, CONVERSATION_STATE, USER_STATE, DIALOG)
 
</code></pre>

<p>Within the initiation of the MainDialog class, you can see that this dialog consists the steps <code class="language-plaintext highlighter-rouge">self.intro_step</code> and <code class="language-plaintext highlighter-rouge">self.act_step</code>. The first step is what greets the user initially
and the act step is what uses the Luis AI to recognize the user’s intent and launch the RecommendationDialog accordingly.</p>

<p><code class="language-plaintext highlighter-rouge">dialogs/main_dialog.py lines 25-33</code></p>
<pre><code class="language-Python3">
        self.add_dialog(TextPrompt(TextPrompt.__name__))
        self.add_dialog(recommendation_dialog)
        self.add_dialog(
            WaterfallDialog(
                "WFDialog", [self.intro_step, self.act_step]
            )
        )

</code></pre>

<h3 id="recommendation-dialog">Recommendation Dialog</h3>

<p>The recommendation dialog relies on the Luis AI input and/or choice promps to determine which genre to use. If the user’s initial response contains a genre or feeling which can be
translated into a genre (if the user says <em>relaxing</em> the bot translates this to <em>classical</em>). Otherwise, we secure a genre through choice prompts. This can be seen in the following snippet:</p>

<p><code class="language-plaintext highlighter-rouge">dialogs/recommendation_dialog.py lines 70-93</code></p>
<pre><code class="language-Python3">
    async def genre_step(
        self, step_context: WaterfallStepContext
    ) -&gt; DialogTurnResult:
        """
        If the user has not provided any emotion in their initial greeting or a genre that they're looking for.
        :param step_context:
        :return DialogTurnResult
        """
        recommendation_details = step_context.options

        # Inquire the user about the genre they'd like to listen to
        if recommendation_details["genre"] == "":
            message_text = "What kind of music would you like me to recommend?"
            prompt_message = MessageFactory.text(
                message_text, message_text, InputHints.expecting_input
            )
            genre_choices = [Choice("rock"), Choice("metal"), Choice("classical"), Choice("jazz"), Choice("pop"), Choice("electronic")]
            return await step_context.prompt(
                ChoicePrompt.__name__, PromptOptions(prompt=prompt_message,choices=genre_choices)
            )
        
        return await step_context.next(recommendation_details)

</code></pre>

<p>To keep the conversation flowing after an initial recommendation has been provided, the dialog contains a confirmation step. The <code class="language-plaintext highlighter-rouge">self.confirmation_step</code> prompts the user on whether they
enjoyed the recommendation. If the user says yes, a new recommendation is given from the current genre in-use. Otherwise, a new prompt is generated for the user to choose a different genre.
On both occasions, the dialogue is replaced with a new to step back into the <code class="language-plaintext highlighter-rouge">self.recommendation_step</code>, but with a different <em>step_context</em> to create the aforementioned behavior.</p>

<p><code class="language-plaintext highlighter-rouge">dialogs/recommendation_dialog.py lines 145-181</code></p>
<pre><code class="language-Python3">
    async def confirmation_step(self, step_context: WaterfallStepContext) -&gt; DialogTurnResult:
        """
        Once a recommendation has been given, take action based on the user's feedback
        :param step_context:
        :return DialogTurnResult:
        """
        print("Executing confirmation step")
        recommendation_details = step_context.options
        feedback = step_context.result

        # If the user liked the recommendation, recommend another song from the same genre
        if feedback:
            message_text = "Glad you enjoyed it!"
            prompt_message = MessageFactory.text(
                message_text, message_text, InputHints.expecting_input
            )

            await step_context.context.send_activity(
                prompt_message
            )

            return await step_context.replace_dialog(RecommendationDialog.__name__, step_context.options)
        else:
            message_text = "Sorry to hear that."
            prompt_message = MessageFactory.text(
                message_text, message_text, InputHints.expecting_input
            )

            await step_context.context.send_activity(
                prompt_message
            )

            step_context.options["genre"] = ""
            return await step_context.replace_dialog(RecommendationDialog.__name__, step_context.options)
</code></pre>

<h2 id="adaptive-cards">Adaptive Cards</h2>

<p>Adaptive cards enhance the user’s experience by showing song information, album art, and providing a link to open the song in a browser. To achieve this feature, the skeleton of the card is formed from
the <code class="language-plaintext highlighter-rouge">cards/songCard.json</code> file.</p>

<p><img src="../images/adaptive-card-song.png" alt="Adaptive Card song display" /></p>

<p>Once the <code class="language-plaintext highlighter-rouge">self.recommendation_step</code> has computed a song to recommend, it reads the <em>songCard.json</em> file and updates the default values based on the selected song. Since each song is created using
the <code class="language-plaintext highlighter-rouge">SongClass.py</code>, extracting song properties is as simple as writing <code class="language-plaintext highlighter-rouge">song.artist</code>.</p>

<p><code class="language-plaintext highlighter-rouge">dialogs/recommendation_dialog.py lines 115-133</code></p>
<pre><code class="language-Python3">        # Update the context genre
        step_context.options["genre"] = genre

        # Randomly select a song from the given genre
        song = songs[genre][random.randrange(3)]
        message_text = "I recommend listening to: "
        prompt_message = MessageFactory.text(
            message_text, message_text, InputHints.expecting_input
        )
        await step_context.context.send_activity(
            prompt_message
        )
		
</code></pre>

<h2 id="interruptions">Interruptions</h2>

<p>Currently the bot supports a termination interruption to end the conversation. To achieve this, every time the dialogue continues; the program checks for termination keywords.
Once the user triggers this interruption, all dialogues are immediately canceled.</p>
:ET